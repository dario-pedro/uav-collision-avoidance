{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hRTa3Ee15WsJ"
   },
   "source": [
    "# Transfer learning with a pretrained MobileNetV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iBMcobPHdD8O"
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import PIL\n",
    "\n",
    "import scipy\n",
    "\n",
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from skimage import transform\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import openpyxl\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TqOt6Sv7AsMi"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "  # %tensorflow_version only exists in Colab.\n",
    "  %tensorflow_version 2.x\n",
    "except Exception:\n",
    "  pass\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Dense, Dropout, LSTM\n",
    "config = ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)\n",
    "\n",
    "keras = tf.keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "NET_TO_PREDICT = \"MBV2\"\n",
    "CSV_NAME = \"TrainedMB\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def path_join(dirname, filenames):\n",
    "    return [os.path.join(dirname, filename) for filename in filenames]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import a function from sklearn to calculate the confusion-matrix.\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "def print_confusion_matrix(cls_pred):\n",
    "    # cls_pred is an array of the predicted class-number for\n",
    "    # all images in the test-set.\n",
    "\n",
    "    # Get the confusion matrix using sklearn.\n",
    "    cm = confusion_matrix(y_true=cls_test,  # True class for test-set.\n",
    "                          y_pred=cls_pred)  # Predicted class.\n",
    "\n",
    "    print(\"Confusion matrix:\")\n",
    "\n",
    "    # Print the confusion matrix as text.\n",
    "    print(cm)\n",
    "\n",
    "    # Print the class-names for easy reference.\n",
    "    for i, class_name in enumerate(class_names):\n",
    "        print(\"({0}) {1}\".format(i, class_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_example_errors(cls_pred):\n",
    "    # cls_pred is an array of the predicted class-number for\n",
    "    # all images in the test-set.\n",
    "\n",
    "    # Boolean array whether the predicted class is incorrect.\n",
    "    incorrect = (cls_pred != cls_test)\n",
    "\n",
    "    # Get the file-paths for images that were incorrectly classified.\n",
    "    image_paths = np.array(image_paths_test)[incorrect]\n",
    "\n",
    "    # Load the first 9 images.\n",
    "    images = load_images(image_paths=image_paths[0:9])\n",
    "\n",
    "    # Get the predicted classes for those images.\n",
    "    cls_pred = cls_pred[incorrect]\n",
    "\n",
    "    # Get the true classes for those images.\n",
    "    cls_true = cls_test[incorrect]\n",
    "\n",
    "    # Plot the 9 images we have loaded and their corresponding classes.\n",
    "    # We have only loaded 9 images so there is no need to slice those again.\n",
    "    plot_images(images=images,\n",
    "                cls_true=cls_true[0:9],\n",
    "                cls_pred=cls_pred[0:9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def example_errors():\n",
    "    # The Keras data-generator for the test-set must be reset\n",
    "    # before processing. This is because the generator will loop\n",
    "    # infinitely and keep an internal index into the dataset.\n",
    "    # So it might start in the middle of the test-set if we do\n",
    "    # not reset it first. This makes it impossible to match the\n",
    "    # predicted classes with the input images.\n",
    "    # If we reset the generator, then it always starts at the\n",
    "    # beginning so we know exactly which input-images were used.\n",
    "    generator_test.reset()\n",
    "\n",
    "    # Predict the classes for all images in the test-set.\n",
    "    y_pred = new_model.predict_generator(generator_test,\n",
    "                                         steps=steps_test)\n",
    "\n",
    "    # Convert the predicted classes from arrays to integers.\n",
    "    cls_pred = np.argmax(y_pred, axis=1)\n",
    "\n",
    "    # Plot examples of mis-classified images.\n",
    "    plot_example_errors(cls_pred)\n",
    "\n",
    "    # Print the confusion matrix.\n",
    "    print_confusion_matrix(cls_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images(image_paths):\n",
    "    # Load the images from disk.\n",
    "    images = [plt.imread(path) for path in image_paths]\n",
    "\n",
    "    # Convert to a numpy array and return it.\n",
    "    return np.asarray(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training_history(history):\n",
    "    # Get the classification accuracy and loss-value\n",
    "    # for the training-set.\n",
    "    acc = history.history['categorical_accuracy']\n",
    "    loss = history.history['loss']\n",
    "\n",
    "    # Get it for the validation-set (we only use the test-set).\n",
    "    val_acc = history.history['val_categorical_accuracy']\n",
    "    val_loss = history.history['val_loss']\n",
    "\n",
    "    # Plot the accuracy and loss-values for the training-set.\n",
    "    plt.plot(acc, linestyle='-', color='b', label='Training Acc.')\n",
    "    plt.plot(loss, 'o', color='b', label='Training Loss')\n",
    "\n",
    "    # Plot it for the test-set.\n",
    "    plt.plot(val_acc, linestyle='--', color='r', label='Test Acc.')\n",
    "    plt.plot(val_loss, 'o', color='r', label='Test Loss')\n",
    "\n",
    "    # Plot title and legend.\n",
    "    plt.title('Training and Test Accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "    # Ensure the plot shows correctly.\n",
    "    plt.show()\n",
    "\n",
    "def plot_images(images, cls_true, cls_pred=None, smooth=True):\n",
    "    assert len(images) == len(cls_true)\n",
    "\n",
    "    # Create figure with sub-plots.\n",
    "    fig, axes = plt.subplots(3, 3)\n",
    "\n",
    "    # Adjust vertical spacing.\n",
    "    if cls_pred is None:\n",
    "        hspace = 0.3\n",
    "    else:\n",
    "        hspace = 0.6\n",
    "    fig.subplots_adjust(hspace=hspace, wspace=0.3)\n",
    "\n",
    "    # Interpolation type.\n",
    "    if smooth:\n",
    "        interpolation = 'spline16'\n",
    "    else:\n",
    "        interpolation = 'nearest'\n",
    "\n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        # There may be less than 9 images, ensure it doesn't crash.\n",
    "        if i < len(images):\n",
    "            # Plot image.\n",
    "            ax.imshow(images[i],\n",
    "                      interpolation=interpolation)\n",
    "\n",
    "            # Name of the true class.\n",
    "            cls_true_name = class_names[cls_true[i]]\n",
    "\n",
    "            # Show true and predicted classes.\n",
    "            if cls_pred is None:\n",
    "                xlabel = \"True: {0}\".format(cls_true_name)\n",
    "            else:\n",
    "                # Name of the predicted class.\n",
    "                cls_pred_name = class_names[cls_pred[i]]\n",
    "\n",
    "                xlabel = \"True: {0}\\nPred: {1}\".format(cls_true_name, cls_pred_name)\n",
    "\n",
    "            # Show the classes as the label on the x-axis.\n",
    "            ax.set_xlabel(xlabel)\n",
    "\n",
    "        # Remove ticks from the plot.\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "\n",
    "    # Ensure the plot is shown correctly with multiple plots\n",
    "    # in a single Notebook cell.\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 224 # All images will be resized to 160x160\n",
    "IMG_SHAPE = (IMG_SIZE, IMG_SIZE, 3)\n",
    "IS_TRAINED_MODEL = True\n",
    "\n",
    "if(IS_TRAINED_MODEL):\n",
    "    loaded_model = tf.keras.models.load_model(\"models/MobileNetV2-50.50-pervideo-ud-1585845356\")\n",
    "    base_model = loaded_model.layers[0]\n",
    "else:\n",
    "    base_model = tf.keras.applications.MobileNetV2(input_shape=IMG_SHAPE,\n",
    "                                                   include_top=False,\n",
    "                                                   weights='imagenet')\n",
    "    \n",
    "global_average_layer = tf.keras.layers.GlobalAveragePooling2D()\n",
    "model = tf.keras.Sequential([base_model,global_average_layer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(image_path):\n",
    "    # Load and resize the image using PIL.\n",
    "    img = PIL.Image.open(image_path)\n",
    "    img_resized = img.resize(input_shape, PIL.Image.LANCZOS)\n",
    "\n",
    "    # Plot the image.\n",
    "    plt.imshow(img_resized)\n",
    "    plt.show()\n",
    "\n",
    "    # Convert the PIL image to a numpy-array with the proper shape.\n",
    "    img_array = np.expand_dims(np.array(img_resized), axis=0)\n",
    "\n",
    "    # the classes of the ImageNet-dataset.\n",
    "    pred = base_model.predict(img_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RpR8HdyMhukJ"
   },
   "outputs": [],
   "source": [
    "optimizer = Adam(lr=1e-5)\n",
    "loss = 'categorical_crossentropy'\n",
    "metrics = ['categorical_accuracy']\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load(filename):\n",
    "   np_image = Image.open(filename)\n",
    "   np_image = np.array(np_image).astype('float32')/255\n",
    "   np_image = transform.resize(np_image, IMG_SHAPE)\n",
    "   np_image = np.expand_dims(np_image, axis=0)\n",
    "   return np_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateDFprediction(filename, pred):\n",
    "    df = pd.DataFrame(data=pred)\n",
    "    df['file'] = filename\n",
    "    # reorder file to be the first\n",
    "    cols = df.columns.tolist()\n",
    "    cols = cols[-1:] + cols[:-1]\n",
    "    df = df[cols]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadOutputVectoresFile(checkfiledir, vectordir, vectorfile):\n",
    "    cols_headings = ['xmin','xmax', 'ymin', 'ymax', 'zmin', 'zmax']\n",
    "    df = pd.read_csv(vectordir + vectorfile, sep=\" \", header=None , names=cols_headings)\n",
    "    df['file'] = df.apply(lambda r: framename(checkfiledir,r,vectorfile),axis = 1)\n",
    "    df['collision'] = df.apply(lambda r: hascollision(r),axis = 1)\n",
    "    df = df[df.file != \"error\"]\n",
    "\n",
    "    # move last two collums to the start\n",
    "    cols = df.columns.tolist()\n",
    "    cols = cols[-2:] + cols[:-2]\n",
    "    \n",
    "    # return data frame\n",
    "    return df[cols]\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generation of the Features starts here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRE_COL = 30 #The amount of frames before collision that are considered to drop frames\n",
    "once = 1\n",
    "\n",
    "\n",
    "dataframes_path = '/tf/notebooks/collision_avoidance/data/2020-03-10/dataframes/' #set the path of excels with labels\n",
    "imagedir = '/tf/notebooks/collision_avoidance/data/2020-03-10/images/' #set the path of the images\n",
    "\n",
    "for file in os.listdir(dataframes_path): #iterator of the all the excels in the directory set in previous line\n",
    "    filename = os.fsdecode(file) #gets the name of the current excel file\n",
    "    df1 = pd.read_excel(dataframes_path + filename) #reads from the selected excel to panda\n",
    "    #for index, row in df1.iterrows(): #iterator of all the rows in the current dataframe excel\n",
    "    #    if(row['collision'] == 1): #finds out which frame has the first collision\n",
    "    #        firstcol = index #stores the index that corresponds to the first collision\n",
    "    #        break \n",
    "    #droptarget = df1.shape[0]-(df1.shape[0]-firstcol+PRE_COL)-int((df1.shape[0]-firstcol+PRE_COL)*1.1) #calculates the frame that we are using to drop non important frames\n",
    "    #if(droptarget > 0):\n",
    "    #    df1 = df1.drop(df1.index[0:droptarget]) #drops the non important non collision frames      \n",
    "    if once: #in the first run our final panda is the same as the first read excel\n",
    "        df2 = df1 #df2 will be our panda with the data from all the frames\n",
    "        once = 0\n",
    "    else:    \n",
    "        df2 = pd.concat([df2, df1]) #on all the other runs concatenates the data read to the complete panda\n",
    "\n",
    "df2 = df2.sort_values(by=['file'],ascending=True) #sorts the panda by column 'file' to order all\n",
    "df2 = df2.set_index('file') # sets the index as the value of the file column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "total_images = df2.shape[0] #stors the total number of rows that correspond to the amount of images to annalize\n",
    "i = 0\n",
    "once2 = 1\n",
    "\n",
    "for i in range(total_images): #iterator of all the images in the dataset\n",
    "    image = load(imagedir+df2.index[i] +'.png') #loads the current image\n",
    "    pred = model.predict(image) # extracts the indexes of the current image\n",
    "    currentPredDF = generateDFprediction(df2.index[i],pred) #generates a panda with the current image name and index values\n",
    "    if once2: # in the first run our final panda only has the values of the first image\n",
    "        df3 = currentPredDF #df3 will be our panda with the indexes of all the images\n",
    "        once2 = 0\n",
    "    else:\n",
    "        df3 = pd.concat([df3, currentPredDF]) #concatenates the new values extracted to our final panda \n",
    "        \n",
    "df3 = df3.set_index('file')# sets the index as the value of the file column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "finalDF = pd.concat([df2,df3], axis=1) #concatenates our two complete pandas into our goal panda, almost there!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features_csv/MBV2-TrainedMB-1586455938.csv\n"
     ]
    }
   ],
   "source": [
    "NAME = f\"{NET_TO_PREDICT}-{CSV_NAME}-{int(time.time())}\"\n",
    "finalDF.to_csv(f\"features_csv/{NAME}.csv\")  #writes our complete panda to a csv! We've made it with no help!!! we can now do the most basic excercise!!\n",
    "print(f\"features_csv/{NAME}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17884.7"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "18826 * 0.95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "transfer_learning.ipynb",
   "private_outputs": true,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
