{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hRTa3Ee15WsJ"
   },
   "source": [
    "# Setup Folders to train CNNs from data on imagedir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iBMcobPHdD8O"
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import PIL\n",
    "\n",
    "import scipy\n",
    "\n",
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from shutil import copyfile\n",
    "\n",
    "from skimage import transform\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import openpyxl\n",
    "\n",
    "from random import random, shuffle\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configure directories paths:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagedir = '/tf/notebooks/collision_avoidance/data/2020-03-10/images/' #set the path of the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def path_join(dirname, filenames):\n",
    "    return [os.path.join(dirname, filename) for filename in filenames]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images(image_paths):\n",
    "    # Load the images from disk.\n",
    "    images = [plt.imread(path) for path in image_paths]\n",
    "\n",
    "    # Convert to a numpy array and return it.\n",
    "    return np.asarray(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load(filename):\n",
    "   np_image = Image.open(filename)\n",
    "   np_image = np.array(np_image).astype('float32')/255\n",
    "   np_image = transform.resize(np_image, IMG_SHAPE)\n",
    "   np_image = np.expand_dims(np_image, axis=0)\n",
    "   return np_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateDFprediction(filename, pred):\n",
    "    df = pd.DataFrame(data=pred)\n",
    "    df['file'] = filename\n",
    "    # reorder file to be the first\n",
    "    cols = df.columns.tolist()\n",
    "    cols = cols[-1:] + cols[:-1]\n",
    "    df = df[cols]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadOutputVectoresFile(checkfiledir, vectordir, vectorfile):\n",
    "    cols_headings = ['xmin','xmax', 'ymin', 'ymax', 'zmin', 'zmax']\n",
    "    df = pd.read_csv(vectordir + vectorfile, sep=\" \", header=None , names=cols_headings)\n",
    "    df['file'] = df.apply(lambda r: framename(checkfiledir,r,vectorfile),axis = 1)\n",
    "    df['collision'] = df.apply(lambda r: hascollision(r),axis = 1)\n",
    "    df = df[df.file != \"error\"]\n",
    "\n",
    "    # move last two collums to the start\n",
    "    cols = df.columns.tolist()\n",
    "    cols = cols[-2:] + cols[:-2]\n",
    "    \n",
    "    # return data frame\n",
    "    return df[cols]\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Delete images from folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, shutil\n",
    "\n",
    "def del_img_in_folder(folder):\n",
    "    for filename in os.listdir(folder):\n",
    "        file_path = os.path.join(folder, filename)\n",
    "        try:\n",
    "            if os.path.isfile(file_path) or os.path.islink(file_path):\n",
    "                os.unlink(file_path)\n",
    "            elif os.path.isdir(file_path):\n",
    "                shutil.rmtree(file_path)\n",
    "        except Exception as e:\n",
    "            print('Failed to delete %s. Reason: %s' % (file_path, e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train data\n",
    "folder_train_collision = '/tf/notebooks/collision_avoidance/data/images/train/collision'\n",
    "del_img_in_folder(folder_train_collision)\n",
    "\n",
    "folder_train_nocollision = '/tf/notebooks/collision_avoidance/data/images/train/no_collision'\n",
    "del_img_in_folder(folder_train_nocollision)\n",
    "\n",
    "# test data\n",
    "folder_test_collision = '/tf/notebooks/collision_avoidance/data/images/test/collision'\n",
    "del_img_in_folder(folder_test_collision)\n",
    "\n",
    "folder_test_nocollision = '/tf/notebooks/collision_avoidance/data/images/test/no_collision'\n",
    "del_img_in_folder(folder_test_nocollision)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Excel and Copy files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "once = 1\n",
    "\n",
    "dataframes_path = '/tf/notebooks/collision_avoidance/data/2020-03-10/dataframes/' #set the path of excels with labels\n",
    "\n",
    "#df2 = pd.read_excel('/tf/notebooks/collision_avoidance/data/2020-03-10/dataframes/video-00093.xlsx')\n",
    "\n",
    "for file in os.listdir(dataframes_path): #iterator of the all the excels in the directory set in previous line\n",
    "    filename = os.fsdecode(file) #gets the name of the current excel file\n",
    "    df1 = pd.read_excel(dataframes_path + filename) #reads from the selected excel to panda\n",
    "    if once: #in the first run our final panda is the same as the first read excel\n",
    "        df2 = df1 #df2 will be our panda with the data from all the frames\n",
    "        once = 0\n",
    "    else:    \n",
    "        df2 = pd.concat([df2, df1]) #on all the other runs concatenates the data read to the complete panda\n",
    "\n",
    "df2 = df2.sort_values(by=['file'],ascending=True) #sorts the panda by column 'file' to order all\n",
    "df2 = df2.set_index('file') # sets the index as the value of the file column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Copy Last % of frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "total_images = df2.shape[0] #stors the total number of rows and decreases one that corresponds to the amount of images to annalize\n",
    "target_path = '/tf/notebooks/collision_avoidance/data/images/' # + test or train  + collision or no collision\n",
    "i = 0\n",
    "\n",
    "PERCENTAGE = 0.05\n",
    "\n",
    "for i in range(total_images): #iterator of all the images in the dataset\n",
    "    \n",
    "    img_name = df2.index[i]\n",
    "    src = imagedir+img_name +'.png' #path to target image\n",
    "    colision = df2.at[img_name,'collision']\n",
    "        \n",
    "    \n",
    "    if random() < PERCENTAGE:\n",
    "        test_or_train = 'test/'\n",
    "    else:\n",
    "        test_or_train = 'train/'\n",
    "    \n",
    "    \n",
    "    \n",
    "    if colision: # in the first run our final panda only has the values of the first image\n",
    "        collision_or_not = 'collision/'\n",
    "    else:\n",
    "        collision_or_not = 'no_collision/'\n",
    "        \n",
    "    dst = target_path + test_or_train + collision_or_not + img_name +'.png'\n",
    "    \n",
    "    copyfile(src, dst)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Copy Last frames of video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "total_images = df2.shape[0] #stors the total number of rows and decreases one that corresponds to the amount of images to annalize\n",
    "target_path = '/tf/notebooks/collision_avoidance/data/images/' # + test or train  + collision or no collision\n",
    "i = 0\n",
    "\n",
    "LAST_VIDEO_NUMBER = 86\n",
    "\n",
    "for i in range(total_images): #iterator of all the images in the dataset\n",
    "    \n",
    "    img_name = df2.index[i]\n",
    "    src = imagedir+img_name +'.png' #path to target image\n",
    "    colision = df2.at[img_name,'collision']\n",
    "    \n",
    "    video_numb = img_name.split('-')[1].lstrip(\"0\")\n",
    "    \n",
    "    \n",
    "    if int(video_numb) > LAST_VIDEO_NUMBER:\n",
    "        test_or_train = 'test/'\n",
    "    else:\n",
    "        test_or_train = 'train/'\n",
    "    \n",
    "    \n",
    "    \n",
    "    if colision: # in the first run our final panda only has the values of the first image\n",
    "        collision_or_not = 'collision/'\n",
    "    else:\n",
    "        collision_or_not = 'no_collision/'\n",
    "        \n",
    "    dst = target_path + test_or_train + collision_or_not + img_name +'.png'\n",
    "    \n",
    "    copyfile(src, dst)\n",
    "           \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Copy the SAME NUMBER of collisions and no collisions - % of frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arrays collision and no_collision ready with 3082 files\n"
     ]
    }
   ],
   "source": [
    "j = 0\n",
    "collision    = []  # list that will store collision sequences and targets\n",
    "no_collision = []  # list that will store NO collision sequences and targets\n",
    "\n",
    "for row_values in df2.values:\n",
    "    # init frame name\n",
    "    frame_name = df2.index[j]\n",
    "    j = j + 1\n",
    "    \n",
    "    # isColllision\n",
    "    if row_values[0] == 1:\n",
    "        collision.append(frame_name)\n",
    "    else:\n",
    "        no_collision.append(frame_name)\n",
    "\n",
    "shuffle(collision)  # shuffle the collision\n",
    "shuffle(no_collision)  # shuffle the no_collision!\n",
    "lower = min(len(collision), len(no_collision))  # what's the shorter length?\n",
    "\n",
    "collision = collision[:lower]  # make sure both lists are only up to the shortest length.\n",
    "no_collision = no_collision[:lower]  # make sure both lists are only up to the shortest length.\n",
    "\n",
    "print(f'arrays collision and no_collision ready with {lower} files')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "PERCENTAGE = 0.05\n",
    "target_path = '/tf/notebooks/collision_avoidance/data/images/' # + test or train  + collision or no collision\n",
    "\n",
    "def copy_from_array(images_names_array, isCollision):\n",
    "    for img_name in images_names_array: #iterator of all the images in the dataset\n",
    "\n",
    "        src = imagedir+img_name +'.png' #path to target image\n",
    "\n",
    "        if random() < PERCENTAGE:\n",
    "            test_or_train = 'test/'\n",
    "        else:\n",
    "            test_or_train = 'train/'\n",
    "\n",
    "        if isCollision: # in the first run our final panda only has the values of the first image\n",
    "            collision_or_not = 'collision/'\n",
    "        else:\n",
    "            collision_or_not = 'no_collision/'\n",
    "\n",
    "        dst = target_path + test_or_train + collision_or_not + img_name +'.png'\n",
    "\n",
    "        copyfile(src, dst)\n",
    "        \n",
    "## execute the copy_from_array on the col and no_col arrays\n",
    "copy_from_array(collision,True)\n",
    "copy_from_array(no_collision,False)\n",
    "\n",
    "print('Filed copied with success')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Copy the SAME NUMBER of collisions and no collisions - % of videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN| arrays collision and no_collision ready with 3004 files\n",
      "TEST| arrays collision and no_collision ready with 78 files\n"
     ]
    }
   ],
   "source": [
    "j = 0\n",
    "train_collision    = []  # TRAIN list that will store collision sequences and targets\n",
    "train_no_collision = []  # TRAIN list that will store NO collision sequences and targets\n",
    "\n",
    "test_collision    = []  # TRAIN list that will store collision sequences and targets\n",
    "test_no_collision = []  # TRAIN list that will store NO collision sequences and targets\n",
    "\n",
    "LAST_VIDEO_NUMBER = 86\n",
    "\n",
    "for row_values in df2.values:\n",
    "    # init frame name\n",
    "    frame_name = df2.index[j]\n",
    "    j = j + 1\n",
    "    video_numb = frame_name.split('-')[1].lstrip(\"0\")\n",
    "    \n",
    "    # Colllision\n",
    "    if row_values[0] == 1:\n",
    "        if int(video_numb) > LAST_VIDEO_NUMBER:\n",
    "            test_collision.append(frame_name)\n",
    "        else:\n",
    "            train_collision.append(frame_name)\n",
    "    # no Collision    \n",
    "    else:\n",
    "        if int(video_numb) > LAST_VIDEO_NUMBER:\n",
    "            test_no_collision.append(frame_name)\n",
    "        else:\n",
    "            train_no_collision.append(frame_name)\n",
    "\n",
    "            \n",
    "## PROCESS TRAIN\n",
    "shuffle(train_collision)  # shuffle the train collision\n",
    "shuffle(train_no_collision)  # shuffle the train no_collision!\n",
    "train_lower = min(len(train_collision), len(train_no_collision))  # what's the train shorter length?\n",
    "\n",
    "train_collision = train_collision[:train_lower]  # make sure both lists are only up to the shortest length.\n",
    "train_no_collision = train_no_collision[:train_lower]  # make sure both lists are only up to the shortest length.\n",
    "\n",
    "\n",
    "## PROCESS TEST\n",
    "shuffle(test_collision)  # shuffle the train collision\n",
    "shuffle(test_no_collision)  # shuffle the train no_collision!\n",
    "test_lower = min(len(test_collision), len(test_no_collision))  # what's the train shorter length?\n",
    "\n",
    "test_collision = test_collision[:test_lower]  # make sure both lists are only up to the shortest length.\n",
    "test_no_collision = test_no_collision[:test_lower]  # make sure both lists are only up to the shortest length.\n",
    "\n",
    "print(f'TRAIN| arrays collision and no_collision ready with {train_lower} files')\n",
    "print(f'TEST| arrays collision and no_collision ready with {test_lower} files')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filed copied with success\n"
     ]
    }
   ],
   "source": [
    "target_path = '/tf/notebooks/collision_avoidance/data/images/' # + test or train  + collision or no collision\n",
    "\n",
    "def copy_from_array_vid(images_names_array, isCollision, isTest):\n",
    "    for img_name in images_names_array: #iterator of all the images in the dataset\n",
    "\n",
    "        src = imagedir+img_name +'.png' #path to target image\n",
    "\n",
    "        if isTest:\n",
    "            test_or_train = 'test/'\n",
    "        else:\n",
    "            test_or_train = 'train/'\n",
    "\n",
    "        if isCollision: # in the first run our final panda only has the values of the first image\n",
    "            collision_or_not = 'collision/'\n",
    "        else:\n",
    "            collision_or_not = 'no_collision/'\n",
    "\n",
    "        dst = target_path + test_or_train + collision_or_not + img_name +'.png'\n",
    "\n",
    "        copyfile(src, dst)\n",
    "        \n",
    "## execute the copy_from_array on the col and no_col arrays\n",
    "copy_from_array_vid(train_collision,isCollision=True,isTest=False)\n",
    "copy_from_array_vid(train_no_collision,isCollision=False,isTest=False)\n",
    "copy_from_array_vid(test_collision,isCollision=True,isTest=True)\n",
    "copy_from_array_vid(test_no_collision,isCollision=False,isTest=True)\n",
    "\n",
    "print('Filed copied with success')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "transfer_learning.ipynb",
   "private_outputs": true,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
